{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ8ICp5manVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac4e4ec2-1bea-46f2-bcb5-4a439b04592b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EKLec3fbahq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "5618c67c-d934-4193-eca4-455c05bd18fd"
      },
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhEAbT_hbhan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "51f2bd84-f635-4bbd-db85-0fd08a2c0eef"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import font_manager, rc\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import platform\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import matplotlib.font_manager as fm\n",
        "#fm._rebuild()\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "\n",
        "import lightgbm as lgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAYHN3hWbmH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "train = pd.read_csv('/gdrive/My Drive/train_new.csv')\n",
        "test = pd.read_csv('/gdrive/My Drive/test_new.csv')\n",
        "ratings = pd.read_csv('/gdrive/My Drive/tv_new.csv')\n",
        "category = pd.read_csv('/gdrive/My Drive/categorized_HJ2.csv') # 카테고리 추가되었습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEQbdyvibnpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train셋의 취급액 이름이 달라서 통일시켜줍니다. 우리의 소원은 통일.\n",
        "train = train.rename(columns = {' 취급액 ':'취급액'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_CTatW0brSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 전처리를 한 번에 해주기 위해서 train, test를 합쳐줍니다.\n",
        "df_all = pd.concat([train, test]).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii69nV2obuB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_cast_time(train): # nan값이 있는 초기 데이터셋을 써야 하기 때문에 가장 먼저 돌려줍니다. 자세한 알고리즘은 창고에서 찾아보세요.\n",
        "\n",
        "    # 일단 nan값을 노출칼럼에만 남기기 위해서 나머지 nan값 전처리 미리 해버리겠습니다.\n",
        "    train['취급액'] = train['취급액'].fillna('0')\n",
        "    train = train[train.상품군 != '무형']\n",
        "\n",
        "    # nan값 있는 애들을 따로 저장해둡니다.\n",
        "    train_yes_nan = train[train['노출(분)'].isnull()]\n",
        "    # nan값 없는 애들을 따로 저장해줍니다. 이놈들로 작업할겁니다.\n",
        "    train_not_nan = train.dropna()\n",
        "\n",
        "    # 인덱스 꼬여서 포문 안 돌아가기 때문에 인덱스 리셋하고 나중에 불러와주기 위해서 따로 저장해줍니다.\n",
        "    train_not_nan_index = train_not_nan.index\n",
        "    # 리셋 인덱스 해줍니다.\n",
        "    train_not_nan_reset_index = train_not_nan.reset_index(drop=True)\n",
        "\n",
        "    # 여기서부터 cast_time, cast_count 포문-----------------------------------------------------\n",
        "    cast_time = []\n",
        "    cast_count = []\n",
        "    time = 0.\n",
        "    count = 1\n",
        "\n",
        "    for i in range(len(train_not_nan_reset_index)):\n",
        "        if i == 0: # 첫번째 행은 이걸로 하십쇼.\n",
        "            time = train_not_nan_reset_index['노출(분)'][i] # 더하지 않고, 자기 노출을 그대로 가져옵니다.\n",
        "            count = 1 # count도 1로 초기화 합니다.\n",
        "            cast_time.append(time) # 그리고 어펜드.\n",
        "            cast_count.append(count) # 그리고 어펜드.\n",
        "        elif train_not_nan_reset_index['상품코드'][i] == train_not_nan_reset_index['상품코드'][i-1]: # 자기의 상품코드가 앞행의 상품코드와 같을 때\n",
        "            time += train_not_nan_reset_index['노출(분)'][i] # 기존 누적된 노출에 자기 노출을 더한다.\n",
        "            count += 1 # count도 1을 더해줍니다.\n",
        "            cast_time.append(time) # 그리고 어펜드.\n",
        "            cast_count.append(count) # 그리고 어펜드.\n",
        "        else: # 근데 자기 상품코드와 앞행의 상품코드가 다르다면, 새로운 방송이 시작된 거겠죠?\n",
        "            time = train_not_nan_reset_index['노출(분)'][i] # 더하지 않고, 자기 노출을 그대로 가져옵니다.\n",
        "            count = 1 # count도 1로 초기화 합니다.\n",
        "            cast_time.append(time) # 그리고 어펜드.\n",
        "            cast_count.append(count) # 그리고 어펜드.\n",
        "    # 포문 끝------------------------------------------------------------  \n",
        "    # 컬럼으로 박아줍니다.\n",
        "    train_not_nan_reset_index['cast_time'] = cast_time\n",
        "    train_not_nan_reset_index['cast_count'] = cast_count\n",
        "    \n",
        "    # 여기서부터 cast_time_sum, cast_count_sum 포문-------------------------------------------------\n",
        "    cast_time_sum = []\n",
        "    cast_count_sum = []\n",
        "\n",
        "    for i in range(len(train_not_nan_reset_index)):\n",
        "        if i == max(train_not_nan_reset_index.index): #마지막은 비교할 다음타자가 없으니 바로 넣기.\n",
        "            cast_time_sum.append(train_not_nan_reset_index['cast_time'][i])\n",
        "            cast_count_sum.append(train_not_nan_reset_index['cast_count'][i])\n",
        "        elif train_not_nan_reset_index['상품코드'][i] == train_not_nan_reset_index['상품코드'][i+1]: # 자기와 다음타자의 상품코드가 같으면\n",
        "            cast_time_sum.append(np.nan)\n",
        "            cast_count_sum.append(np.nan)\n",
        "        else: # 자기와 다음타자의 상품코드가 다르면\n",
        "            cast_time_sum.append(train_not_nan_reset_index['cast_time'][i])\n",
        "            cast_count_sum.append(train_not_nan_reset_index['cast_count'][i])\n",
        "            \n",
        "    # 포문 끝----------------------------------------------------------------------\n",
        "    # 칼럼으로 박아줍니다.\n",
        "    train_not_nan_reset_index['cast_time_sum'] = cast_time_sum\n",
        "    train_not_nan_reset_index['cast_count_sum'] = cast_count_sum\n",
        "    # 백필로 nan값 채워줍니다.\n",
        "    train_not_nan_reset_index.fillna(method='bfill', inplace=True)\n",
        "    \n",
        "\n",
        "    # 원래 인덱스 다시 넣어줍니다.\n",
        "    train_not_nan_reset_index.index = train_not_nan_index\n",
        "    # 컨캣으로 밑으로 붙여주고,\n",
        "    train_concat = pd.concat([train_not_nan_reset_index, train_yes_nan], axis=0)\n",
        "    # 소트 인덱스 먼저 하고,\n",
        "    train_concat_sort_index = train_concat.sort_index()\n",
        "    # ffill 로 채워줍니다. 끝. 이거 너무 힘들었다 진짜 레알.\n",
        "    train = train_concat_sort_index.fillna(method='ffill')\n",
        "    \n",
        "    # 누적 방송 시간 비율 칼럼을 만들어줍니다.\n",
        "    train['cast_time_ratio'] = train.cast_time / train.cast_time_sum\n",
        "    \n",
        "    # 인덱스 리셋해줍니다.\n",
        "    train = train.reset_index(drop=True)\n",
        "    \n",
        "    # 다이어트\n",
        "    train['cast_count'] = train.cast_count.astype(np.int16)\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7spYR5fGbvqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = make_cast_time(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Tr7A01bzYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기본 전처리 함수\n",
        "def preprocessing_1(df):\n",
        "    \n",
        "    # 취급액과 판매단가 수치형 변수로 바꾸기.\n",
        "    df['취급액'] = df['취급액'].apply(lambda x: x.replace(',', ''))\n",
        "    df['판매단가'] = df['판매단가'].apply(lambda x: x.replace(',', ''))\n",
        "    df['취급액'] = df['취급액'].astype(np.int32)\n",
        "    df['판매단가'] = df['판매단가'].astype(np.int32)\n",
        "    \n",
        "    # 칼럼명 너무 어려우니까 쪼금만 바꿔줍니다.\n",
        "    #df = df.rename(columns = {' 취급액 ':'취급액'})\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRm29N6Lb8hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = preprocessing_1(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIRBbQgQb-G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 상품명 전처리 함수\n",
        "def preprocessing_3(train):\n",
        "    # 1. 일시불/무이자/없음\n",
        "    train.loc[train['상품명'].str.contains('일시불') == True, \"상품명_plan\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('일\\)') == True, \"상품명_plan\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('무이자') == True, \"상품명_plan\"] = '2'\n",
        "    train.loc[train['상품명'].str.contains('무\\)') == True, \"상품명_plan\"] = '2'\n",
        "    train['상품명_plan'] = train['상품명_plan'].fillna('0')\n",
        "\n",
        "    # 2. 추가구성/단품구성\n",
        "    train.loc[train['상품명'].str.contains('\\+') == True, \"상품명_add\"] = '1'\n",
        "    train['상품명_add'] = train['상품명_add'].fillna('0')\n",
        "\n",
        "    # 3. 기타/삼성/LG\n",
        "    train.loc[train['상품명'].str.contains('삼성') == True, \"상품명_maker\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('LG') == True, \"상품명_maker\"] = '2'\n",
        "    train['상품명_maker'] = train['상품명_maker'].fillna('0')\n",
        "\n",
        "    # 4. 세트구성/단품구성\n",
        "    train.loc[train['상품명'].str.contains('세트') == True, \"상품명_set\"] = '1'\n",
        "    train['상품명_set'] = train['상품명_set'].fillna('0')\n",
        "\n",
        "    # 5. 여성/남성/없음\n",
        "    train.loc[train['상품명'].str.contains('여성') == True, \"상품명_sex\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('브라') == True, \"상품명_sex\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('란쥬') == True, \"상품명_sex\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('블라우스') == True, \"상품명_sex\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('밍크') == True, \"상품명_sex\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('남성') == True, \"상품명_sex\"] = '2'\n",
        "    train.loc[train['상품명'].str.contains('드로즈') == True, \"상품명_sex\"] = '2'\n",
        "    train.loc[train['상품명'].str.contains('트렁크') == True, \"상품명_sex\"] = '2'\n",
        "    train['상품명_sex'] = train['상품명_sex'].fillna('0')\n",
        "    \n",
        "    # 6. 아동/성인\n",
        "    train.loc[train['상품명'].str.contains('주니어') == True, \"상품명_kid\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('여아') == True, \"상품명_kid\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('남아') == True, \"상품명_kid\"] = '1'\n",
        "    train.loc[train['상품명'].str.contains('아동') == True, \"상품명_kid\"] = '1'\n",
        "    train['상품명_kid'] = train['상품명_kid'].fillna('0')\n",
        "\n",
        "    # category로 형변환해서 다이어트 시켜줍니다.\n",
        "    train['상품명_plan'] = train['상품명_plan'].astype('category')\n",
        "    train['상품명_add'] = train['상품명_add'].astype('category')\n",
        "    train['상품명_maker'] = train['상품명_maker'].astype('category')\n",
        "    train['상품명_set'] = train['상품명_set'].astype('category')\n",
        "    train['상품명_sex'] = train['상품명_sex'].astype('category')\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKuoTG3Nb_UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = preprocessing_3(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgp0n6bcAkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_fake_weight(train):\n",
        "    fake_weight = []\n",
        "    weight = 1\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        if i == 0: # 첫번째 행은 이걸로 하십쇼.\n",
        "            weight = 1 # count도 1로 초기화 합니다.\n",
        "            fake_weight.append(weight) # 그리고 어펜드.\n",
        "            \n",
        "        elif train['마더코드'][i] == train['마더코드'][i-1]: # 자기의 마더코드가 앞행의 것과 같을 때\n",
        "            if train['판매단가'][i] < train['판매단가'][i-1]: # 자기의 단가가 앞행의 것보다 작으면(같으면 안됨)\n",
        "                weight +=1 # 가중치 1을 더하고,\n",
        "                fake_weight.append(weight) # 그리고 어펜드\n",
        "            else: # 자기의 단가가 앞행의 것과 같거나 더 크면(더 클 수는 없음.)\n",
        "                weight = 1 # 가중치 1로 초기화\n",
        "                fake_weight.append(weight)\n",
        "                \n",
        "        else: # 근데 자기 마더코드와 앞행의 마더코드가 다르다면, 새로운 방송이 시작된 거겠죠?\n",
        "            weight = 1 # 가중치 1로 초기화\n",
        "            fake_weight.append(weight)\n",
        "            \n",
        "    train['fake_weight'] = fake_weight\n",
        "    train['fake_weight'] = train.fake_weight.apply(lambda x: -(x*x))\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aw2LvfTcBlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = make_fake_weight(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcdbNNmcCsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_fake(train):\n",
        "    \n",
        "    # 더 정확한 변수 생성을 위해 기계가 걸러내지 못하는 조건을 쳐내줍니다.\n",
        "    train_fake = train[train.상품명_plan == '0'] # 할부플랜이 다른 애들 쳐내기\n",
        "    train_fake = train_fake[train_fake.상품명_sex == '0'] # 성별이 다른 애들 쳐내기.\n",
        "    \n",
        "    # 포문 돌리기 위해 인덱스 리셋 해줍니다.\n",
        "    train_fake.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return train_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpaLYT34cDzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_fake_weight2(train):\n",
        "    fake_weight = []\n",
        "    weight = 0\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        if i == 0: # 첫번째 행은 이걸로 하십쇼.\n",
        "            weight = 0 # count도 1로 초기화 합니다.\n",
        "            fake_weight.append(weight) # 그리고 어펜드.\n",
        "            \n",
        "        elif train['마더코드'][i] == train['마더코드'][i-1]: # 자기의 마더코드가 앞행의 것과 같을 때\n",
        "            if train['판매단가'][i] == train['판매단가'][i-1]: # 자기의 단가가 앞행의 것과 같을 때\n",
        "                if train['방송일시'][i] == train['방송일시'][i-1]:\n",
        "                    if train['상품코드'][i] != train['상품코드'][i-1]: # 상품코드는 일치하지 않으면 조건 성립\n",
        "                        weight -=1 # 가중치 1을 빼고,\n",
        "                        fake_weight.append(weight) # 그리고 어펜드\n",
        "                    else: # 상품코드까지 같으면 동일 상품.\n",
        "                        weight = 0\n",
        "                        fake_weight.append(weight)\n",
        "                else: #방송일시가 다르면 새로운 방송 시작\n",
        "                    weight = 0 # 가중치 0로 초기화\n",
        "                    fake_weight.append(weight)\n",
        "            else: # 판매단가가 다르면 다른 상품\n",
        "                weight = 0 # 가중치 0로 초기화\n",
        "                fake_weight.append(weight)\n",
        "        else: # 근데 자기 마더코드와 앞행의 마더코드가 다르다면, 새로운 방송이 시작된 거겠죠?\n",
        "            weight = 0 # 가중치 1로 초기화\n",
        "            fake_weight.append(weight)\n",
        "            \n",
        "    train['fake_weight2'] = fake_weight\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YzIAGhNcErJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fake = make_train_fake(df_all)\n",
        "df_fake = make_fake_weight2(df_fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PjTxRpWcevi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기존 데이터에 합쳐줍니다.\n",
        "df_all = pd.merge(df_all, df_fake[['방송일시','마더코드','상품코드','상품명','판매단가', 'fake_weight2']],\n",
        "                 on=['방송일시','마더코드','상품코드','상품명','판매단가'], how='left')\n",
        "\n",
        "# 빈 값은 전부 0으로 채워줍니다.\n",
        "df_all['fake_weight2'] = df_all['fake_weight2'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mr5u_H7cfp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = pd.read_csv('/gdrive/My Drive/categorized_HJ2.csv') # 카테고리 추가되었습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFL5HJP3cniM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 난 값 먼저 채워 줍니다.\n",
        "category['cat3'] = category.apply(lambda x: x['cat2'] if x['cat3'] != x['cat3'] else x['cat3'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFEwmSbGc-IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_to_merge(df):\n",
        "    # merge를 위해 datetime으로 바꿔줍니다..\n",
        "    df['방송일시'] = pd.to_datetime(df['방송일시'], errors='coerce')\n",
        "    df['방송일시'] = df['방송일시'].astype(str)\n",
        "    \n",
        "    # key 칼럼을 만들어줍니다. 방송일시만으로는 안되니, 방송일시+상품명을 해줍니다.\n",
        "    df['key'] = df['방송일시'] + df['상품명']\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "515DJttdc_nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_merging(df1, df2):\n",
        "    # df1이 왼쪽, df2가 오른쪽입니다.\n",
        "    df3 = pd.merge(df1, df2[['key','ratings_mean','cat1','cat2','cat3']], how='left', on=['key'])\n",
        "    df3 = df3.drop('key', axis=1) # key 칼럼은 드랍.\n",
        "    \n",
        "    return df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq5ZpGGsdAj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = preprocessing_to_merge(df_all)\n",
        "category = preprocessing_to_merge(category)\n",
        "df_all = preprocessing_merging(df_all, category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2LRHCkqdBxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 방송일시 쪼개기 전처리 함수\n",
        "def preprocessing_4(train):\n",
        "    # datetime으로 바꿔줍니다.\n",
        "    train['방송일시'] = pd.to_datetime(train['방송일시'], errors='coerce')\n",
        "   \n",
        "    # 월일이 다음날로 넘어가는 것을 막기 위해서 3시간씩 앞으로 땡겨줍니다. 마지막에 다시 더해줘야 합니다.\n",
        "    delta = datetime.timedelta(hours=3)\n",
        "    train['방송일시'] = train.방송일시.apply(lambda x: x - delta)\n",
        "\n",
        "    # dayofweek는 날짜에서 요일(월~일)을 가져오는 기능입니다.\n",
        "    # 값은 0(월), 1(화), 2(수), 3(목), 4(금), 5(토), 6(일) 을 나타냅니다.\n",
        "    train[\"방송일시_dow\"] = train[\"방송일시\"].dt.dayofweek\n",
        "\n",
        "    # 요일 외에 다른 정보를 가져오기 위해서 다시 string으로 바꿔줍니다.\n",
        "    train['방송일시'] = train.방송일시.astype(str)\n",
        "\n",
        "    # MMDDhhmm 정보를 가져옵니다.\n",
        "    train['방송일시_MM'] = train['방송일시'].apply(lambda x: x[5:7])\n",
        "    train['방송일시_DD'] = train['방송일시'].apply(lambda x: x[8:10])\n",
        "    train['방송일시_hh'] = train['방송일시'].apply(lambda x: x[11:13])\n",
        "    train['방송일시_mm'] = train['방송일시'].apply(lambda x: x[14:16])\n",
        "\n",
        "    # schedule 관련 칼럼을 더 만들어보겠습니다. # MMDD # DDHH # HHMM # weekday/weekends\n",
        "    train['방송일시_MMDD'] = train['방송일시_MM'] + train['방송일시_DD']\n",
        "    train['방송일시_DDhh'] = train['방송일시_DD'] + train['방송일시_hh']\n",
        "    train['방송일시_hhmm'] = train['방송일시_hh'] + train['방송일시_mm']\n",
        "    train['방송일시_MMDDhh'] = train['방송일시_MM'] + train['방송일시_DD'] + train['방송일시_hh']\n",
        "\n",
        "    # mmmm_1 은 1일 사이클로 분단위로 환산한 것\n",
        "    # mmmm_2 는 1달 사이클로 분단위로 환산한 것\n",
        "    # mmmm_3 는 1년 사이클로 분단위로 환산한 것\n",
        "    train['방송일시_mmmm_1'] = train['방송일시_hh'].astype(int) * train['방송일시_mm'].astype(int) * 60\n",
        "    train['방송일시_mmmm_2'] = train['방송일시_DD'].astype(int) * train['방송일시_hh'].astype(int) * train['방송일시_mm'].astype(int) * 60\n",
        "    train['방송일시_mmmm_3'] = train['방송일시_MM'].astype(int) * train['방송일시_DD'].astype(int) * train['방송일시_hh'].astype(int) * train['방송일시_mm'].astype(int) * 60\n",
        "\n",
        "    # weekday = 1 / weekends = 0\n",
        "    train.loc[train.방송일시_dow == 5, '방송일시_dow2'] = '0'\n",
        "    train.loc[train.방송일시_dow == 6, '방송일시_dow2'] = '0'\n",
        "    train['방송일시_dow2'] = train.방송일시_dow2.fillna('1')\n",
        "    \n",
        "    #다이어트\n",
        "    train['방송일시_dow'] = train.방송일시_dow.astype(np.int16)\n",
        "    train['방송일시_MM'] = train.방송일시_MM.astype('category')\n",
        "    train['방송일시_DD'] = train.방송일시_DD.astype('category')\n",
        "    train['방송일시_hh'] = train.방송일시_hh.astype('category')\n",
        "    train['방송일시_mm'] = train.방송일시_mm.astype('category')\n",
        "    train['방송일시_MMDD'] = train.방송일시_MMDD.astype('category')\n",
        "    train['방송일시_DDhh'] = train.방송일시_DDhh.astype('category')\n",
        "    train['방송일시_hhmm'] = train.방송일시_hhmm.astype('category')\n",
        "    train['방송일시_dow2'] = train.방송일시_dow2.astype('category')\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTqFEquNdDYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "df_all = preprocessing_4(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2-pmOFOdEma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_nlp(train):\n",
        "    # 제품명에서 불필요한 요소 전처리\n",
        "    new_product_name = []\n",
        "\n",
        "    re_stop = re.compile(\"\"\"\\([가-힣]{1,5}\\+[가-힣]{1,5}\\)|\\(?무이자\\)?\\s?|\\(?일시불\\)?\\s?|\\(?초특가\\)?\\s?|\\(?무\\)\\s?|\\(?유\\)\\s?|\\(?일\\)\\s?|무료체험|\n",
        "    |포함|국내[가-힣]+\\s|무료설치|\\s?신제품\\s?|\\s?패키지\\s?|[0-9]+종|풀코디|set|SET|풀세트|[0-9]+세트|더블팩|싱글팩|[0-9]{1,2}\\+[0-9]{1,2}|[0-9]{1,2}인용|[0-9]{1,2}박스|[0-9\\.]{1,4}미터|[0-9\\.]{1,4}kg|[0-9\\.]{1,4}[kKgG]|[0-9]{1,3}[벌롤종단구대P개통병포미봉팩장gL매]|\n",
        "    |\\s[0-9\\.]{1,4}[Mm]|\\(.{1,10}\\)$|^\\(.?\\)|^[0-9]{2,4}\\s|\\s+[0-9]{2,4}\\s|[0-9]{2,4}년\\s|[0-9]{2,4}년형\\s|시즌[0-9]|[0-9]{1,3}\\%|\\(.{1,20}\\)$|기본형|고급형|오리지널|[대중소大中小]형|.{1,10}by|,|\\s?총[0-9\\s]|^[가-힣a-zA-Z]{3,3}의|\n",
        "    |S\\/S|F\\/W|f\\/w|s\\/s|[가-힣]+형\\s|[슈퍼]{0,2}싱글|\\s[SQK퀸킹]{1,2}\\s|[SQK퀸킹]{1,2}$|[가-힣]{0,2}사이즈\"\"\")\n",
        "\n",
        "    remnants = re.compile('[\",g\\+lL-]\\s|ml|_|\\sx|[\\[\\]\\］!\"#$%&\\'()*+,./:;<=>?@\\^_`{|}~-]|\\s종$|\\s[0-9]+\\s|\\s{2,}')\n",
        "\n",
        "    for i in train.상품명:\n",
        "        tmp = re_stop.sub(' ',i)\n",
        "        tmp = tmp.strip()\n",
        "        tmp = remnants.sub(' ',tmp)\n",
        "        new_product_name.append(tmp.strip())\n",
        "    \n",
        "    train['new_상품명'] = new_product_name\n",
        "    \n",
        "    # 상품명에서 브랜드 추출\n",
        "    train['상품명_brand'] = train['new_상품명'].apply(lambda x: x[:2])\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83SDvgyqdHmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "df_all = pre_nlp(df_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvWPYMTodIyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "naver = pd.read_csv('/gdrive/My Drive/naver.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Vk5BcNdStM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outside_feature_naver(train, naver):\n",
        "    # 먼저 합쳐줍니다.\n",
        "    train = pd.merge(train, naver, on='상품명', how='left')\n",
        "    \n",
        "    # 전처리 해줍니다.\n",
        "    train['review_counts'] = train['review_counts'].fillna(0)\n",
        "    train['internet_price'] = train['internet_price'].fillna(0)\n",
        "    train['review_counts'] = train['review_counts'].astype(str)\n",
        "    train['internet_price'] = train['internet_price'].astype(str)\n",
        "    train['review_counts'] = train['review_counts'].apply(lambda x: x.replace(',',''))\n",
        "    train['internet_price'] = train['internet_price'].apply(lambda x: x.replace(',',''))\n",
        "    train['internet_price'] = train['internet_price'].apply(lambda x: x.replace('원',''))\n",
        "    train['review_counts'] = train['review_counts'].astype(int)\n",
        "    train['internet_price'] = train['internet_price'].astype(int)\n",
        "\n",
        "    # 오차를 컬럼으로 만들어줍니다.\n",
        "    train['price_minus'] = train['판매단가'] - train['internet_price']\n",
        "\n",
        "    # 네이버에 서칭이 되는지 여부를 알려줍니다.\n",
        "    train['search_naver'] = train['internet_price'] + train['review_counts']\n",
        "    train['search_naver'] = train['search_naver'].apply(lambda x: 0 if x == 0 else 1)\n",
        "    \n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z03sZVfSImW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = outside_feature_naver(df_all, naver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyU4ICNQdVfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기상청 통계 파일 읽기\n",
        "weather = pd.read_csv('/gdrive/My Drive/OBS_ASOS_TIM_20200902192155.csv', encoding='latin1')\n",
        "columns = ['location_id','location','date','temperature']\n",
        "weather.columns = columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9pLT1sEJtOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outside_feature_weather(weather):\n",
        "    # datetime으로 바꿔줍니다.\n",
        "    weather['date'] = pd.to_datetime(weather['date'], errors='coerce')\n",
        "\n",
        "    # 월일이 다음날로 넘어가는 것을 막기 위해서 3시간씩 앞으로 땡겨줍니다. 마지막에 다시 더해줘야 합니다.\n",
        "    delta = datetime.timedelta(hours=3)\n",
        "    weather['date'] = weather.date.apply(lambda x: x - delta)\n",
        "\n",
        "    # 요일 외에 다른 정보를 가져오기 위해서 다시 string으로 바꿔줍니다.\n",
        "    weather['date'] = weather.date.astype(str)\n",
        "    \n",
        "    # key column 만들어주기.\n",
        "    weather['방송일시_MMDDhh'] = weather['date'].apply(lambda x: x[5:7]) + weather['date'].apply(lambda x: x[8:10]) + weather['date'].apply(lambda x: x[11:13])\n",
        "\n",
        "    # 필요없는 칼럼은 미리 버려줍니다.\n",
        "    weather.drop(['location_id', 'location', 'date'], axis=1, inplace=True)\n",
        "    \n",
        "    return weather"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmDfb8UsJvDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather = outside_feature_weather(weather)\n",
        "\n",
        "# 합쳐줍니다.\n",
        "df_all = pd.merge(df_all, weather, on='방송일시_MMDDhh', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PXqWoFDJ5_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings = pd.read_csv(r'/gdrive/My Drive/tv_new.csv')\n",
        "# 합치기 좋게 행렬 축을 바꿔줍니다.\n",
        "ratings_melt = pd.melt(ratings, id_vars=['시간대'])\n",
        "# 평균 시청률이 있습니다. 없애줍니다.\n",
        "ratings_melt.drop(ratings_melt[ratings_melt['variable'].str.contains('to')].index, axis=0, inplace=True)\n",
        "ratings_melt.drop(ratings_melt[ratings_melt['시간대'].str.contains('월')].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE5nrg45KM9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "change = 0\n",
        "change_label = []\n",
        "\n",
        "for i in range(len(df_all)):\n",
        "    if i == 0: # 첫번째 행은 이걸로 하십쇼.\n",
        "        change = 1 # 방송 시작이니 1을 줍니다.\n",
        "        change_label.append(change) # 그리고 어펜드.\n",
        "\n",
        "    elif df_all['마더코드'][i] == df_all['마더코드'][i-1]: # 자기의 마더코드가 앞행의 것과 같을 때\n",
        "        change = 0 # 기존 방송이니 0을 줍니다.\n",
        "        change_label.append(change) # 그리고 어펜드.\n",
        "        \n",
        "    else: # 근데 자기 마더코드와 앞행의 마더코드가 다르다면, 새로운 방송이 시작된 거겠죠?\n",
        "        change = 1 # 방송 시작이니 1을 줍니다.\n",
        "        change_label.append(change) # 그리고 어펜드.\n",
        "\n",
        "df_all['change_label'] = change_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkLuU7SFKUiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시청률 df는 편하게 change_label 을 그냥 1로 때려박습니다.\n",
        "ratings_melt['change_label'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQmiVQZ2Kakc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train의 방송일시를 datetime 으로 바꿔서 키 값으로 줍니다.\n",
        "df_all['ratings_key'] = pd.to_datetime(df_all.방송일시)\n",
        "# ratings 도 마찬가지.\n",
        "ratings_melt['ratings_key'] = pd.to_datetime((ratings_melt.variable + \" \" + ratings_melt.시간대))\n",
        "# train이 3시간 당겨져 있으니, ratings도 3시간 당겨줍니다.\n",
        "delta = datetime.timedelta(hours=3)\n",
        "ratings_melt['ratings_key'] = ratings_melt.ratings_key.apply(lambda x: x - delta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4lujswKiK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 합쳐줍니다.\n",
        "df_all = pd.merge(df_all, ratings_melt[['ratings_key','change_label', 'value']], on=['change_label','ratings_key'], how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktb8ZLVVKj4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 방송 시작 시청률만 넣어주기 때문에 nan값이 생깁니다. 전부 ffill로 채워주면 점수가 떨어지고 0을 넣어주면 올라갑니다... \n",
        "df_all.value = df_all.value.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNAubPRNKnZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 키값은 드랍\n",
        "df_all.drop('ratings_key', axis=1, inplace=True)\n",
        "# 칼럼명은 변경\n",
        "df_all.rename(columns = {'value':'ratings_start'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd5p-TLjKp_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가격이 끝에 9xxxx 으로 끝나는 애들을 따로 피쳐로 빼봅시다.\n",
        "\n",
        "df_all['판매단가'] = df_all['판매단가'].astype(str)\n",
        "df_all.loc[df_all['판매단가'].str.contains('900') == True, \"가격_9x\"] = '1'\n",
        "df_all.loc[df_all['판매단가'].str.contains('900') == False, \"가격_9x\"] = '0'\n",
        "df_all['판매단가'] = df_all['판매단가'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QHwfV0tKxqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stock_crawler(code):\n",
        "\n",
        "    for c, i in zip(code, range(len(code))):\n",
        "        \n",
        "        url = 'https://finance.naver.com/item/sise_day.nhn' # URL은 고정\n",
        "        result = []\n",
        "        tdtext_list = ['날짜', c]\n",
        "\n",
        "        for num in range(16, 43): # 페이지 범위 지정\n",
        "            params = {'code' : c, # 지수 코드 지정\n",
        "                      'page' : f'{num}'}\n",
        "\n",
        "            resp = requests.get(url, params = params)\n",
        "            soup = BeautifulSoup(resp.content, 'html.parser')\n",
        "\n",
        "            for tr in soup.find_all('tr')[2:14]:\n",
        "                new_dict = { }\n",
        "                td_list = tr.find_all('td')\n",
        "                if not td_list[0].text.strip():\n",
        "                    continue\n",
        "                for i in range(2):\n",
        "                    new_dict[tdtext_list[i]] = td_list[i].text.strip()\n",
        "                result.append(new_dict)\n",
        "\n",
        "        globals()['stock_{}'.format(c)] = pd.DataFrame(result, columns = tdtext_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6h07ShTLE3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "code = ['143860', '098560', '228790', '228800', '227560', '227550', '307510']\n",
        "stock_crawler(code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2v-GbcYLGR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 다 합쳐줍니다. 함수로 하고 싶은데,너무 귀찮습니다. 알고리즘 짜기. 그냥 노가다 뜁니다.\n",
        "stock_all = pd.merge(stock_098560, stock_143860, on='날짜')\n",
        "stock_all = pd.merge(stock_all, stock_227550, on='날짜')\n",
        "stock_all = pd.merge(stock_all, stock_227560, on='날짜')\n",
        "stock_all = pd.merge(stock_all, stock_228790, on='날짜')\n",
        "stock_all = pd.merge(stock_all, stock_228800, on='날짜')\n",
        "stock_all = pd.merge(stock_all, stock_307510, on='날짜')\n",
        "\n",
        "# key값을 만들기 위해 귀찮지만 형변환 두 단계\n",
        "stock_all['날짜'] = pd.to_datetime(stock_all['날짜'], errors='coerce')\n",
        "stock_all['날짜'] = stock_all['날짜'].astype(str)\n",
        "\n",
        "# 1월 1일 자료가 없는 관계로 그 이전 종가를 가져온다.\n",
        "stock_all.replace({'2018-12-28': '2019-01-01'}, inplace=True)\n",
        "\n",
        "# 컴퓨터가 인식하도록 int 로 수치를 바꿔줍니다.\n",
        "\n",
        "for col in stock_all.columns:\n",
        "    stock_all[col] = stock_all[col].apply(lambda x: x.replace(',',''))\n",
        "    if col == '날짜':\n",
        "        pass\n",
        "    else:\n",
        "        stock_all[col] = stock_all[col].astype(np.int16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLMggD_uLcb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 귀찮지만 train에도 만들어주기.\n",
        "df_all['날짜'] = df_all['방송일시'].apply(lambda x: x[:10])\n",
        "df_all['날짜'] = df_all['날짜'].astype(str)\n",
        "\n",
        "df_all = pd.merge(df_all, stock_all, on='날짜', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce6k6t7uLiLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all= df_all.fillna(method='ffill')\n",
        "df_all.drop(['날짜'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1EjE-1LpSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 상품별 최대 판매단가 추가\n",
        "\n",
        "tmp = df_all[['상품명','판매단가']].groupby('상품명').max()[['판매단가']].reset_index()\n",
        "df_all = pd.merge(df_all, tmp, on='상품명', how='left')\n",
        "df_all.rename({'판매단가_x':'판매단가','판매단가_y':'할인'}, axis=1, inplace= True)\n",
        "df_all['할인여부'] = df_all['할인'] - df_all['판매단가']\n",
        "\n",
        "df_all.drop(['할인'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7QeJWXxL8VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간대별 평균 취급액 추가(train default 변수)\n",
        "\n",
        "tmp = df_all.groupby('방송일시_hhmm').mean()[['취급액']].reset_index()\n",
        "df_all = pd.merge(df_all, tmp, on='방송일시_hhmm', how='left')\n",
        "df_all.rename({'취급액_y':'mean_amt_by_hhmm','취급액_x':'취급액'}, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hl0wf9QMkzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간대별로 4파트로 나눕니다. 아래는 민수의 구분\n",
        "\n",
        "list_0 = ['03', '04', '05', '06', '07','08'] # 낮12시 이전\n",
        "list_1 = ['09', '10', '11', '12', '13','14', '15', '16', '17'] # 낮 12시부터\n",
        "list_2 = ['18', '19', '20', '21', '22', '23'] # 밤 9시부터\n",
        "\n",
        "# 시간대별로 4파트로 나눕니다. 아래는 왕수의 구분\n",
        "\n",
        "list_4 = ['03', '21', '22', '23'] # 심야시간대, 03, 21, 22, 23\n",
        "list_5 = ['04', '05', '06', '07', '08', '09'] # 낮 12시까지 오전\n",
        "list_6 = ['10', '11', '12', '13', '14', '15'] # 저녁 18시 이전까지 오후, 나머진 저녁"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XlSdCMKMsRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all['time_cat'] = df_all['방송일시_hh'].apply(lambda x:0 if x in list_0 else(1 if x in list_1 else (2 if x in list_2 else 3)))\n",
        "df_all['time_cat2'] = df_all['방송일시_hh'].apply(lambda x:0 if x in list_4 else(1 if x in list_5 else (2 if x in list_6 else 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U12VOeTeMy-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e537f2aa-419d-4eab-9097-220deaff98b7"
      },
      "source": [
        "# 판매단가 카테고리화\n",
        "\n",
        "df_all['판매단가_cat'] = df_all['판매단가'].apply(lambda x: 0 if x <= 15000 else (1 if x<=30000 else (2 if x <=45000 else (3 if x <= 60000 else (4 if x <= 100000 else 5)))))\n",
        "df_all['판매단가_cat'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    20731\n",
              "4     6964\n",
              "3     6588\n",
              "2     5054\n",
              "1      748\n",
              "0        3\n",
              "Name: 판매단가_cat, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRyXpv_oNE85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aabff72b-ea19-465a-cb18-1faedcd09771"
      },
      "source": [
        "kospi = pd.read_csv('/gdrive/My Drive/코스피지수 내역.csv')\n",
        "kospi.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>날짜</th>\n",
              "      <th>종가</th>\n",
              "      <th>오픈</th>\n",
              "      <th>고가</th>\n",
              "      <th>저가</th>\n",
              "      <th>거래량</th>\n",
              "      <th>변동 %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019년 12월 30일</td>\n",
              "      <td>2,197.67</td>\n",
              "      <td>2,202.62</td>\n",
              "      <td>2,208.04</td>\n",
              "      <td>2,195.65</td>\n",
              "      <td>416.40M</td>\n",
              "      <td>-0.30%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019년 12월 27일</td>\n",
              "      <td>2,204.21</td>\n",
              "      <td>2,183.70</td>\n",
              "      <td>2,215.55</td>\n",
              "      <td>2,177.40</td>\n",
              "      <td>490.17M</td>\n",
              "      <td>0.29%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019년 12월 26일</td>\n",
              "      <td>2,197.93</td>\n",
              "      <td>2,192.22</td>\n",
              "      <td>2,198.01</td>\n",
              "      <td>2,183.90</td>\n",
              "      <td>571.31M</td>\n",
              "      <td>0.36%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019년 12월 24일</td>\n",
              "      <td>2,190.08</td>\n",
              "      <td>2,206.23</td>\n",
              "      <td>2,206.23</td>\n",
              "      <td>2,187.58</td>\n",
              "      <td>569.97M</td>\n",
              "      <td>-0.62%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019년 12월 23일</td>\n",
              "      <td>2,203.71</td>\n",
              "      <td>2,208.22</td>\n",
              "      <td>2,209.20</td>\n",
              "      <td>2,196.43</td>\n",
              "      <td>502.03M</td>\n",
              "      <td>-0.02%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              날짜        종가        오픈        고가        저가      거래량    변동 %\n",
              "0  2019년 12월 30일  2,197.67  2,202.62  2,208.04  2,195.65  416.40M  -0.30%\n",
              "1  2019년 12월 27일  2,204.21  2,183.70  2,215.55  2,177.40  490.17M   0.29%\n",
              "2  2019년 12월 26일  2,197.93  2,192.22  2,198.01  2,183.90  571.31M   0.36%\n",
              "3  2019년 12월 24일  2,190.08  2,206.23  2,206.23  2,187.58  569.97M  -0.62%\n",
              "4  2019년 12월 23일  2,203.71  2,208.22  2,209.20  2,196.43  502.03M  -0.02%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1IfP2y6TCzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kospi = kospi[['날짜','변동 %']]\n",
        "kospi['변동 %'] = kospi['변동 %'].apply(lambda x: x[:-1])\n",
        "kospi['변동 %'] = kospi['변동 %'].astype(float)\n",
        "\n",
        "kospi['날짜'] = kospi['날짜'].apply(lambda x: x[6:12])\n",
        "kospi['날짜'] = kospi['날짜'].apply(lambda x: x.replace('월 ',''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohNiCmXNTDLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = pd.merge(df_all, kospi, left_on = '방송일시_MMDD',right_on = '날짜',how='left')\n",
        "del df_all['날짜']\n",
        "df_all['변동 %'] = df_all['변동 %'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkQjyOJATDH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 같은 시간에 방송한거 same 이름으로 묶어줌\n",
        "df_all['same'] = 1\n",
        "for i in range(1,len(df_all)):\n",
        "  if df_all['cast_count'][i] == df_all['cast_count'][i-1]:\n",
        "    df_all['same'][i] = df_all['same'][i-1]\n",
        "  else:\n",
        "    df_all['same'][i] = df_all['same'][i-1] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2tKhyJzTDF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 같은 시간에 여러 품목 방송했는지 알기 위해 cast_count_com 변수 새로 생성\n",
        "df_all = pd.merge(df_all, df_all.groupby('same').sum().reset_index()[['same','cast_count']], on ='same', how='left')\n",
        "df_all.rename({'cast_count_x':'cast_count', 'cast_count_y':'cast_count_com'}, axis=1, inplace= True)\n",
        "\n",
        "# 최종 비교 위해 com 또 생성\n",
        "df_all['com'] = df_all['cast_count'] - df_all['cast_count_com']\n",
        "\n",
        "# 같은 방송 여러 품목에 fw라는 순번을 붙여줌\n",
        "tmp = df_all.copy()\n",
        "tmp = tmp[tmp['com'] != 0]\n",
        "tmp.reset_index(drop=True, inplace=True)\n",
        "tmp['fw'] = 1\n",
        "for i in range(1, len(tmp)):\n",
        "  if tmp['same'][i] == tmp['same'][i-1]:\n",
        "    tmp['fw'][i] = tmp['fw'][i-1]+1\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orlIyO74TDC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 다시 train 데이터에 fw 붙여주기 fake_weight3으로 이름 붙이기\n",
        "df_all = pd.merge(df_all, tmp[['방송일시','상품명','fw']], on =['방송일시','상품명'], how = 'left')\n",
        "df_all.rename({'fw':'fake_weight3'},axis=1,inplace=True)\n",
        "df_all.drop(['same','cast_count_com'], axis=1, inplace=True)\n",
        "#train['fw'] = train['fw'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3atIgjhTDBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all['fake_weight3']= df_all['fake_weight3'].fillna(0)\n",
        "df_all['fake_weight3'] = df_all['fake_weight3'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIsepFUfTC_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7fbce174-a5dc-435e-bf54-0ac1124317a9"
      },
      "source": [
        "# 한 방송에 여러상품 포함하면 1 아니면 0\n",
        "df_all['com'] = df_all['com'].apply(lambda x: 1 if x==0 else 0)\n",
        "df_all['com'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26335\n",
              "1    13753\n",
              "Name: com, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbpyqdZCTC9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17e65128-7fbc-4c55-bf67-d31000ae7f29"
      },
      "source": [
        "search = pd.read_excel('/gdrive/My Drive/datalab.xlsx',skiprows=6)\n",
        "search.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>날짜</th>\n",
              "      <th>NS홈쇼핑 NS</th>\n",
              "      <th>날짜.1</th>\n",
              "      <th>롯데홈쇼핑</th>\n",
              "      <th>날짜.2</th>\n",
              "      <th>GS홈쇼핑</th>\n",
              "      <th>날짜.3</th>\n",
              "      <th>현대홈쇼핑</th>\n",
              "      <th>날짜.4</th>\n",
              "      <th>CJ홈쇼핑</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>17.30971</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>56.97459</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>38.37021</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>50.46388</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>8.50646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>17.66025</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>60.25098</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>37.89114</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>46.27374</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>7.57869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>14.87696</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>62.30282</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>37.54060</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>49.87263</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>7.12766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>13.96087</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>59.56159</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>37.43310</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>49.71606</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>6.97576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>14.40957</td>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>65.72410</td>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>50.29562</td>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>63.80313</td>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>8.42466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           날짜  NS홈쇼핑 NS        날짜.1     롯데홈쇼핑        날짜.2     GS홈쇼핑  \\\n",
              "0  2019-01-01  17.30971  2019-01-01  56.97459  2019-01-01  38.37021   \n",
              "1  2019-01-02  17.66025  2019-01-02  60.25098  2019-01-02  37.89114   \n",
              "2  2019-01-03  14.87696  2019-01-03  62.30282  2019-01-03  37.54060   \n",
              "3  2019-01-04  13.96087  2019-01-04  59.56159  2019-01-04  37.43310   \n",
              "4  2019-01-05  14.40957  2019-01-05  65.72410  2019-01-05  50.29562   \n",
              "\n",
              "         날짜.3     현대홈쇼핑        날짜.4    CJ홈쇼핑  \n",
              "0  2019-01-01  50.46388  2019-01-01  8.50646  \n",
              "1  2019-01-02  46.27374  2019-01-02  7.57869  \n",
              "2  2019-01-03  49.87263  2019-01-03  7.12766  \n",
              "3  2019-01-04  49.71606  2019-01-04  6.97576  \n",
              "4  2019-01-05  63.80313  2019-01-05  8.42466  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz4gATFYTC7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7abd569f-f270-4b16-a881-4b4b39a1ac11"
      },
      "source": [
        "search = search[['날짜','NS홈쇼핑 NS']]\n",
        "search['날짜'] = search['날짜'].apply(lambda x: x[5:])\n",
        "search['날짜'] = search['날짜'].apply(lambda x: x.replace('-',''))\n",
        "search.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>날짜</th>\n",
              "      <th>NS홈쇼핑 NS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0101</td>\n",
              "      <td>17.30971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0102</td>\n",
              "      <td>17.66025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0103</td>\n",
              "      <td>14.87696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0104</td>\n",
              "      <td>13.96087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0105</td>\n",
              "      <td>14.40957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     날짜  NS홈쇼핑 NS\n",
              "0  0101  17.30971\n",
              "1  0102  17.66025\n",
              "2  0103  14.87696\n",
              "3  0104  13.96087\n",
              "4  0105  14.40957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7951ssLTC5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = pd.merge(df_all, search, left_on ='방송일시_MMDD', right_on = '날짜', how = 'left')\n",
        "df_all.rename({'NS홈쇼핑 NS':'search_compare'},axis=1, inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ364OQzM38q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 라벨인코딩 숫자가 많아지니 함수로 만들어버립니다.\n",
        "def label_encoding(train_, columns, number):\n",
        "    length = range(number)\n",
        "    for c, i in zip(columns, length):\n",
        "        # 라벨인코더 피팅\n",
        "        globals()['encoder_{}:'.format(i)] = LabelEncoder()\n",
        "        globals()['encoder_{}:'.format(i)].fit(train_[c].values)\n",
        "        \n",
        "        # 트레인셋에 트랜스폼\n",
        "        train_['encoding_{}:'.format(c)] = globals()['encoder_{}:'.format(i)].transform(train_[c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-LSSZdqNb4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코딩할 컬럼을 리스트로 넣어줍니다.\n",
        "columns = ['상품명', '상품군', '상품명_brand', 'new_상품명','cat1','cat2','cat3']\n",
        "number = len(columns)\n",
        "\n",
        "# 함수로 바로 처리.\n",
        "label_encoding(df_all, columns, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28SN6EYvNdOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all.drop(['index'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqcged4zNfaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_all['상품명_kid'] = df_all['상품명_kid'].astype(int)\n",
        "df_all['가격_9x'] = df_all['가격_9x'].astype(int)\n",
        "\n",
        "train = df_all[:37372]\n",
        "test = df_all[37372:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdRt3zQ1NhGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "adcbf7a2-bf4c-44b9-eba2-7bcf9eb672e3"
      },
      "source": [
        "# 예측 값 추정이 불가능한 취급액 0원인 애들 제거해줍니다.\n",
        "\n",
        "train = train[train.취급액 != 0]\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35379, 72)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHj3kRJBNiWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de031c02-af46-43dc-9c3e-e2002944d2c5"
      },
      "source": [
        "# train 셋의 아웃라이어를 제거해봅니다...1억 이상의 취급액을 가진 데이터가 약 1% 정도 있습니다.\n",
        "\n",
        "train = train[train.취급액 < 100000000]\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35196, 72)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM3lHVytUWyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_, test_ = train_test_split(train, test_size=0.2, random_state=529)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUWM3NLaNjT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['노출(분)', '마더코드', '상품코드','판매단가',\n",
        "       'cast_time', 'cast_count', 'cast_time_sum', 'cast_count_sum',\n",
        "       'cast_time_ratio', '상품명_plan', '상품명_add', '상품명_maker', '상품명_set',\n",
        "       '상품명_sex', '상품명_kid', 'fake_weight', 'fake_weight2', 'ratings_mean',\n",
        "       '방송일시_dow', '방송일시_MM', '방송일시_DD', '방송일시_hh',\n",
        "       '방송일시_mm', '방송일시_MMDD', '방송일시_DDhh', '방송일시_hhmm', '방송일시_MMDDhh',\n",
        "       '방송일시_mmmm_1', '방송일시_mmmm_2', '방송일시_mmmm_3', '방송일시_dow2', 'review_counts', 'internet_price', 'price_minus',\n",
        "       'search_naver', 'temperature', 'change_label', 'ratings_start', '가격_9x',\n",
        "       '할인여부', 'mean_amt_by_hhmm', 'time_cat', 'time_cat2', '판매단가_cat',\n",
        "       'encoding_상품명:', 'encoding_상품군:', 'encoding_상품명_brand:',\n",
        "       'encoding_new_상품명:','encoding_cat1:', 'encoding_cat2:','encoding_cat3:',\n",
        "       '변동 %', 'com', 'fake_weight3','search_compare'\n",
        "           ]\n",
        "\n",
        "label = '취급액'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4Nx7C-Ud4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c376d139-90ea-4676-9176-7f00aa464189"
      },
      "source": [
        "len(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ2vUpW2N2PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rating_mean 은 일단 제외하고 학습합니다.\n",
        "# 변수 순서가 바뀌면 점수가 바뀝니다.\n",
        "\n",
        "X_train = train_[features].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[features].values \n",
        "y_test = test_[label].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQD1xRWWN3n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_log = np.log(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nu_xzlpN5Cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestRegressor(n_jobs=3,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTx0nRCRPGYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee45410d-1156-43c7-ea4b-da12ebc38378"
      },
      "source": [
        "def mape(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.56769016000426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drP4GmO5U3-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "6658b8b5-81c9-45c2-edbd-99ca20ab8587"
      },
      "source": [
        "!pip install boruta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boruta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/11/583f4eac99d802c79af9217e1eff56027742a69e6c866b295cce6a5a8fc2/Boruta-0.3-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▉                          | 10kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from boruta) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->boruta) (0.16.0)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELS27klYVrbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d05db706-8c70-4831-c152-6b7b0b26bf21"
      },
      "source": [
        "from boruta import BorutaPy\n",
        "\n",
        "cols = train.columns\n",
        "x = train[features].values\n",
        "y = train[label].values\n",
        "log_y = np.log(y)\n",
        "#  randomforest 및 boruta 객체 형성\n",
        "rf = RandomForestRegressor()\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=529)\n",
        "feat_selector.fit(x, log_y)\n",
        "\n",
        "# 변수선택 이후 데이터 형성\n",
        "X_filtered = feat_selector.transform(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2, random_state=529)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "\n",
        "# # Boruta 적용 결과 저장\n",
        "# new_cols = []\n",
        "# for x in range(len(feat_selector.support_)):\n",
        "#     if feat_selector.support_[x] == True:\n",
        "#         new_cols.append(cols[x])\n",
        "\n",
        "# # 결과 확인\n",
        "# print('이용 컬럼 :{}'.format(new_cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t55\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t3\n",
            "Rejected: \t28\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t3\n",
            "Rejected: \t28\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t3\n",
            "Rejected: \t28\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t3\n",
            "Rejected: \t28\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t3\n",
            "Rejected: \t28\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t24\n",
            "Tentative: \t2\n",
            "Rejected: \t29\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t25\n",
            "Tentative: \t1\n",
            "Rejected: \t29\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t26\n",
            "Tentative: \t0\n",
            "Rejected: \t29\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t26\n",
            "Tentative: \t0\n",
            "Rejected: \t29\n",
            "이용 컬럼 :['방송일시', '노출(분)', '마더코드', '상품코드', '상품명', 'cast_time', 'cast_count_sum', '상품명_kid', 'cat2', '방송일시_dow', '방송일시_MM', '방송일시_DDhh', '방송일시_hhmm', '방송일시_MMDDhh', '방송일시_mmmm_2', 'review_counts', 'price_minus', 'temperature', 'change_label', '가격_9x', '098560', '143860', '227550', '228790', '228800', '307510']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q2lREjHeofE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "45839cff-a509-4c5c-bf5e-a4c769472d07"
      },
      "source": [
        "# Boruta 적용 결과 저장\n",
        "new_cols = []\n",
        "cols = train[features].columns\n",
        "for x in range(len(feat_selector.support_)):\n",
        "    if feat_selector.support_[x] == True:\n",
        "        new_cols.append(cols[x])\n",
        "\n",
        "# 결과 확인\n",
        "print('이용 컬럼 :{}'.format(new_cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이용 컬럼 :['노출(분)', '마더코드', '상품코드', '판매단가', 'cast_time', 'cast_time_ratio', '상품명_maker', '방송일시_dow', '방송일시_MMDD', '방송일시_hhmm', '방송일시_MMDDhh', 'review_counts', 'internet_price', 'price_minus', 'temperature', 'mean_amt_by_hhmm', 'time_cat2', 'encoding_상품명:', 'encoding_상품군:', 'encoding_new_상품명:', 'encoding_cat1:', 'encoding_cat2:', 'encoding_cat3:', 'com', 'fake_weight3', 'search_compare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv8TMDqSlr7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rating_mean 은 일단 제외하고 학습합니다.\n",
        "# 변수 순서가 바뀌면 점수가 바뀝니다.\n",
        "\n",
        "X_train = train_[new_cols].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols].values \n",
        "y_test = test_[label].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzK-DyVhl2q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_log = np.log(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qQuDNIJl2oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestRegressor(n_jobs=3,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY1OePCjX8gH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5739938e-9197-40d0-e8fc-fd507b79ad5a"
      },
      "source": [
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.90556334695656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV3yA_iQYB2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d85de93f-247a-4cb7-c221-2fc81c228fab"
      },
      "source": [
        "len(new_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CyyKCLAozcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_cols_boruta = new_cols.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuPaU_fio3OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "# rating_mean 은 일단 제외하고 학습합니다.\n",
        "# 변수 순서가 바뀌면 점수가 바뀝니다.\n",
        "\n",
        "X_train = train_[features].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[features].values \n",
        "y_test = test_[label].values\n",
        "\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "x = train[features].values\n",
        "y = train[label].values\n",
        "y_log = np.log(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3n_GWs1o3KH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "47939f96-9d35-4534-a04c-8a1cd8fdf7ee"
      },
      "source": [
        "sel = SelectFromModel(RandomForestRegressor(random_state=529))\n",
        "sel.fit(x, y_log)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                                criterion='mse', max_depth=None,\n",
              "                                                max_features='auto',\n",
              "                                                max_leaf_nodes=None,\n",
              "                                                max_samples=None,\n",
              "                                                min_impurity_decrease=0.0,\n",
              "                                                min_impurity_split=None,\n",
              "                                                min_samples_leaf=1,\n",
              "                                                min_samples_split=2,\n",
              "                                                min_weight_fraction_leaf=0.0,\n",
              "                                                n_estimators=100, n_jobs=None,\n",
              "                                                oob_score=False,\n",
              "                                                random_state=529, verbose=0,\n",
              "                                                warm_start=False),\n",
              "                max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l16CfY4o3Hv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "38d61bd1-b33e-4b60-d2c4-d8465bba8d4c"
      },
      "source": [
        "sel.get_support()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False,  True,  True, False, False, False,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False,  True, False, False, False,\n",
              "       False, False, False, False,  True, False,  True, False,  True,\n",
              "       False, False, False, False, False,  True, False,  True,  True,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVmgndRco27e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1539373-91d1-425b-e147-cece30e10f4c"
      },
      "source": [
        "selected_feat= train[features].columns[(sel.get_support())]\n",
        "len(selected_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaxIXBkeo250",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ae9e1db0-b98e-475a-d7d6-b042e2c821b5"
      },
      "source": [
        "selected_feat.values.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['판매단가',\n",
              " 'cast_time',\n",
              " 'cast_time_ratio',\n",
              " 'internet_price',\n",
              " 'mean_amt_by_hhmm',\n",
              " 'time_cat2',\n",
              " 'encoding_상품명:',\n",
              " 'encoding_cat3:',\n",
              " 'com',\n",
              " 'fake_weight3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWMX1Vwjo23s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_cols_sklearn = selected_feat.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyWPilPmo21P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rating_mean 은 일단 제외하고 학습합니다.\n",
        "# 변수 순서가 바뀌면 점수가 바뀝니다.\n",
        "\n",
        "X_train = train_[new_cols_sklearn].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_sklearn].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGZeXfKGo2zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRjBQGiMo2w9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67e93900-b5e3-4fdc-bdb6-d239e5c3f604"
      },
      "source": [
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.18191883550131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WDbKHdcsjwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recursive feature elimination\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(RandomForestRegressor(), 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2amDX0osj3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "478e9183-f090-4c5d-93a9-6243ddf209c4"
      },
      "source": [
        "fit = rfe.fit(x, y_log)\n",
        "print( fit.n_features_) \n",
        "print(\"Selected Features: %s\"% fit.support_) \n",
        "print(\"Feature Ranking: %s\"% fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "Selected Features: [False False False  True  True False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False  True False False False\n",
            " False False False False  True False False False  True False False False\n",
            " False False  True False  True  True False]\n",
            "Feature Ranking: [17 18  3  1  1 33 40 30  1 26 28 22 38 32 46 29 45 19 13 35 23 27 41 15\n",
            " 11  7  1 25 21 14 31 12  1 10 44  6 37 43 36 34  1 42  4 39  1 16 24  5\n",
            " 20  8  1  9  1  1  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukbxUITn4US4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "70ebfa01-2f31-4041-916a-b1c278684788"
      },
      "source": [
        "ord = [3,4,8,26,32,40,44,50,52,53]\n",
        "new_cols_RFE = []\n",
        "for i in ord:\n",
        "  new_cols_RFE.append(features[i])\n",
        "new_cols_RFE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['판매단가',\n",
              " 'cast_time',\n",
              " 'cast_time_ratio',\n",
              " '방송일시_MMDDhh',\n",
              " 'internet_price',\n",
              " 'mean_amt_by_hhmm',\n",
              " 'encoding_상품명:',\n",
              " 'encoding_cat3:',\n",
              " 'com',\n",
              " 'fake_weight3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua65Kwhzu5oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_[new_cols_RFE].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_RFE].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqZTSIT6u5um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbd24520-0cf1-486d-e4af-1653d5c8e772"
      },
      "source": [
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)\n",
        "\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.34033606472361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5jp4t1mbEd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87E_QSPvbb5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train[features].values\n",
        "y = train[label].values\n",
        "y_log = np.log(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86bRd747bEb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recursive feature elimination\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(RandomForestRegressor(), 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "794niuT6bEYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "be0a4977-a014-4ae1-fac0-439744e2dc9e"
      },
      "source": [
        "fit = rfe.fit(x, y_log)\n",
        "print( fit.n_features_) \n",
        "print(\"Selected Features: %s\"% fit.support_) \n",
        "print(\"Feature Ranking: %s\"% fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "Selected Features: [False False  True  True  True False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False  True False False  True\n",
            " False False False False  True False  True False  True False False  True\n",
            " False False  True False  True  True  True]\n",
            "Feature Ranking: [12 13  1  1  1 28 35 25  1 21 23 17 33 29 40 24 41 14  8 31 18 22 36 10\n",
            "  6  2  1 20 16  9 26  7  1  5 39  1 27 38 32 30  1 37  1 34  1 11 19  1\n",
            " 15  3  1  4  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPv-YDG-bEV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "d86b2fd3-347d-4d8a-a99b-ace9b16ba45f"
      },
      "source": [
        "ord = [2,3,4,8,26,32,35,40,42,44,47,50,52,53,54]\n",
        "new_cols_RFE = []\n",
        "for i in ord:\n",
        "  new_cols_RFE.append(features[i])\n",
        "new_cols_RFE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['상품코드',\n",
              " '판매단가',\n",
              " 'cast_time',\n",
              " 'cast_time_ratio',\n",
              " '방송일시_MMDDhh',\n",
              " 'internet_price',\n",
              " 'temperature',\n",
              " 'mean_amt_by_hhmm',\n",
              " 'time_cat2',\n",
              " 'encoding_상품명:',\n",
              " 'encoding_new_상품명:',\n",
              " 'encoding_cat3:',\n",
              " 'com',\n",
              " 'fake_weight3',\n",
              " 'search_compare']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJpwyYhKbETP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d80adfe-6573-47fd-f671-90006b7c7563"
      },
      "source": [
        "X_train = train_[new_cols_RFE].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_RFE].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)\n",
        "\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.777473540006525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaxUrd37bEQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJgKSfD6bEOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recursive feature elimination\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(RandomForestRegressor(), 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWFNsYO_bEMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "a2c31f0d-fc13-48a9-8234-5fb4fe00683c"
      },
      "source": [
        "fit = rfe.fit(x, y_log)\n",
        "print( fit.n_features_) \n",
        "print(\"Selected Features: %s\"% fit.support_) \n",
        "print(\"Feature Ranking: %s\"% fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "Selected Features: [False False  True  True  True False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            "  True  True  True False False False False False  True  True False  True\n",
            " False False False False  True False  True False  True False False  True\n",
            " False  True  True  True  True  True  True]\n",
            "Feature Ranking: [ 7  8  1  1  1 22 30 20  1 15 18 12 28 23 35 19 36 10  3 26 13 17 31  5\n",
            "  1  1  1 16 11  4 21  2  1  1 34  1 25 33 27 24  1 32  1 29  1  6 14  1\n",
            "  9  1  1  1  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POpo7-Y1bEJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f07e79e9-b43e-466c-cfed-47881947d964"
      },
      "source": [
        "ord = [2,3,4,8,24,25,26,32,33,35,40,42,44,47,49,50,51,52,53,54]\n",
        "print(len(ord))\n",
        "new_cols_RFE = []\n",
        "for i in ord:\n",
        "  new_cols_RFE.append(features[i])\n",
        "print(new_cols_RFE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "['상품코드', '판매단가', 'cast_time', 'cast_time_ratio', '방송일시_DDhh', '방송일시_hhmm', '방송일시_MMDDhh', 'internet_price', 'price_minus', 'temperature', 'mean_amt_by_hhmm', 'time_cat2', 'encoding_상품명:', 'encoding_new_상품명:', 'encoding_cat2:', 'encoding_cat3:', '변동 %', 'com', 'fake_weight3', 'search_compare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxJgAeNIbEFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e036083a-b9fc-480c-9fcd-dad3eac7f413"
      },
      "source": [
        "X_train = train_[new_cols_RFE].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_RFE].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)\n",
        "\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.79954608000143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpzILlvFbEB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWgP_SSDwvtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recursive feature elimination\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(RandomForestRegressor(), 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV0PBS8cwv3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "b939173b-2bb0-495c-83cb-9f13d1cce304"
      },
      "source": [
        "fit = rfe.fit(x, y_log)\n",
        "print( fit.n_features_) \n",
        "print(\"Selected Features: %s\"% fit.support_) \n",
        "print(\"Feature Ranking: %s\"% fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "Selected Features: [False False  True  True  True False False False  True False False False\n",
            " False False False False False False  True False False False False  True\n",
            "  True  True  True False False  True False  True  True  True False  True\n",
            " False False False False  True False  True False  True  True False  True\n",
            " False  True  True  True  True  True  True]\n",
            "Feature Ranking: [ 2  3  1  1  1 17 25 15  1  9 13  7 23 18 30 14 31  4  1 22  8 12 26  1\n",
            "  1  1  1 11  6  1 16  1  1  1 29  1 19 28 21 20  1 27  1 24  1  1 10  1\n",
            "  5  1  1  1  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTZKEBd1wvyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "3394d77f-3f0b-4a47-c893-6a303d89dba0"
      },
      "source": [
        "ord = [2,3,4,8,18,23,24,25,26,29,31,32,33,35,40,42,44,45,47,49,50,51,52,53,54]\n",
        "print(len(ord))\n",
        "new_cols_RFE = []\n",
        "for i in ord:\n",
        "  new_cols_RFE.append(features[i])\n",
        "print(new_cols_RFE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "['상품코드', '판매단가', 'cast_time', 'cast_time_ratio', '방송일시_dow', '방송일시_MMDD', '방송일시_DDhh', '방송일시_hhmm', '방송일시_MMDDhh', '방송일시_mmmm_3', 'review_counts', 'internet_price', 'price_minus', 'temperature', 'mean_amt_by_hhmm', 'time_cat2', 'encoding_상품명:', 'encoding_상품군:', 'encoding_new_상품명:', 'encoding_cat2:', 'encoding_cat3:', '변동 %', 'com', 'fake_weight3', 'search_compare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9E9-gsfwvqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f808526d-9cd3-464f-832e-c1bdac10f357"
      },
      "source": [
        "X_train = train_[new_cols_RFE].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_RFE].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)\n",
        "\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.360352541540166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm3j92dyu5lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atlnk5Ad86zP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "0b3068f7-18b8-4744-a9d8-efb1f797cd46"
      },
      "source": [
        "# recursive feature elimination\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(RandomForestRegressor(), 30)\n",
        "\n",
        "fit = rfe.fit(x, y_log)\n",
        "print( fit.n_features_) \n",
        "print(\"Selected Features: %s\"% fit.support_) \n",
        "print(\"Feature Ranking: %s\"% fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "Selected Features: [ True  True  True  True  True False False False  True False False False\n",
            " False False False False False  True  True False False False False  True\n",
            "  True  True  True False  True  True False  True  True  True False  True\n",
            " False False False False  True False  True False  True  True False  True\n",
            "  True  True  True  True  True  True  True]\n",
            "Feature Ranking: [ 1  1  1  1  1 12 20 10  1  5  7  2 17 13 26  9 25  1  1 15  3  8 21  1\n",
            "  1  1  1  6  1  1 11  1  1  1 24  1 14 23 18 16  1 22  1 19  1  1  4  1\n",
            "  1  1  1  1  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_oZ3Yx-868b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "918e92c1-236c-4f05-b39f-67bc4efa84bd"
      },
      "source": [
        "ord = [0,1,2,3,4,8,17,18,23,24,25,26,28,29,31,32,33,35,40,42,44,45,47,48,49,50,51,52,53,54]\n",
        "print(len(ord))\n",
        "new_cols_RFE = []\n",
        "for i in ord:\n",
        "  new_cols_RFE.append(features[i])\n",
        "print(new_cols_RFE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "['노출(분)', '마더코드', '상품코드', '판매단가', 'cast_time', 'cast_time_ratio', 'ratings_mean', '방송일시_dow', '방송일시_MMDD', '방송일시_DDhh', '방송일시_hhmm', '방송일시_MMDDhh', '방송일시_mmmm_2', '방송일시_mmmm_3', 'review_counts', 'internet_price', 'price_minus', 'temperature', 'mean_amt_by_hhmm', 'time_cat2', 'encoding_상품명:', 'encoding_상품군:', 'encoding_new_상품명:', 'encoding_cat1:', 'encoding_cat2:', 'encoding_cat3:', '변동 %', 'com', 'fake_weight3', 'search_compare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gN-xeo1865Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53066f3f-489f-45d4-e6ad-650ffea39aac"
      },
      "source": [
        "X_train = train_[new_cols_RFE].values \n",
        "y_train = train_[label].values\n",
        "X_test = test_[new_cols_RFE].values \n",
        "y_test = test_[label].values\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1,\n",
        "                           random_state=592)\n",
        "\n",
        "rf.fit(X_train, y_train_log)\n",
        "pred_log = rf.predict(X_test)\n",
        "\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.10062044236769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI8P-dfLu5dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHAcr4R_sj1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class GeneticSelector():\n",
        "#     def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
        "#                  n_children, mutation_rate):\n",
        "#         # Estimator \n",
        "#         self.estimator = estimator\n",
        "#         # Number of generations\n",
        "#         self.n_gen = n_gen\n",
        "#         # Number of chromosomes in population\n",
        "#         self.size = size\n",
        "#         # Number of best chromosomes to select\n",
        "#         self.n_best = n_best\n",
        "#         # Number of random chromosomes to select\n",
        "#         self.n_rand = n_rand\n",
        "#         # Number of children created during crossover\n",
        "#         self.n_children = n_children\n",
        "#         # Probablity of chromosome mutation\n",
        "#         self.mutation_rate = mutation_rate\n",
        "        \n",
        "#         if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
        "#             raise ValueError(\"The population size is not stable.\")  \n",
        "            \n",
        "#     def initilize(self):\n",
        "#         population = []\n",
        "#         for i in range(self.size):\n",
        "#             chromosome = np.ones(self.n_features, dtype=np.bool)\n",
        "#             mask = np.random.rand(len(chromosome)) < 0.3\n",
        "#             chromosome[mask] = False\n",
        "#             population.append(chromosome)\n",
        "#         return population\n",
        "\n",
        "#     def fitness(self, population):\n",
        "#         X, y = self.dataset\n",
        "#         scores = []\n",
        "#         for chromosome in population:\n",
        "#             score = mape(X[:,chromosome], y)\n",
        "#             scores.append(score)\n",
        "#         scores, population = np.array(scores), np.array(population) \n",
        "#         inds = np.argsort(scores)\n",
        "#         return list(scores[inds]), list(population[inds,:])\n",
        "\n",
        "#     def select(self, population_sorted):\n",
        "#         population_next = []\n",
        "#         for i in range(self.n_best):\n",
        "#             population_next.append(population_sorted[i])\n",
        "#         for i in range(self.n_rand):\n",
        "#             population_next.append(random.choice(population_sorted))\n",
        "#         random.shuffle(population_next)\n",
        "#         return population_next\n",
        "\n",
        "#     def crossover(self, population):\n",
        "#         population_next = []\n",
        "#         for i in range(int(len(population)/2)):\n",
        "#             for j in range(self.n_children):\n",
        "#                 chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
        "#                 child = chromosome1\n",
        "#                 mask = np.random.rand(len(child)) > 0.5\n",
        "#                 child[mask] = chromosome2[mask]\n",
        "#                 population_next.append(child)\n",
        "#         return population_next\n",
        "\t\n",
        "#     def mutate(self, population):\n",
        "#         population_next = []\n",
        "#         for i in range(len(population)):\n",
        "#             chromosome = population[i]\n",
        "#             if random.random() < self.mutation_rate:\n",
        "#                 mask = np.random.rand(len(chromosome)) < 0.05\n",
        "#                 chromosome[mask] = False\n",
        "#             population_next.append(chromosome)\n",
        "#         return population_next\n",
        "\n",
        "#     def generate(self, population):\n",
        "#         # Selection, crossover and mutation\n",
        "#         scores_sorted, population_sorted = self.fitness(population)\n",
        "#         population = self.select(population_sorted)\n",
        "#         population = self.crossover(population)\n",
        "#         population = self.mutate(population)\n",
        "#         # History\n",
        "#         self.chromosomes_best.append(population_sorted[0])\n",
        "#         self.scores_best.append(scores_sorted[0])\n",
        "#         self.scores_avg.append(np.mean(scores_sorted))\n",
        "        \n",
        "#         return population\n",
        "\n",
        "#     def fit(self, X, y):\n",
        " \n",
        "#         self.chromosomes_best = []\n",
        "#         self.scores_best, self.scores_avg  = [], []\n",
        "        \n",
        "#         self.dataset = X, y\n",
        "#         self.n_features = X.shape[1]\n",
        "        \n",
        "#         population = self.initilize()\n",
        "#         for i in range(self.n_gen):\n",
        "#             population = self.generate(population)\n",
        "            \n",
        "#         return self \n",
        "    \n",
        "#     @property\n",
        "#     def support_(self):\n",
        "#         return self.chromosomes_best[-1]\n",
        "\n",
        "#     def plot_scores(self):\n",
        "#         plt.plot(self.scores_best, label='Best')\n",
        "#         plt.plot(self.scores_avg, label='Average')\n",
        "#         plt.legend()\n",
        "#         plt.ylabel('Scores')\n",
        "#         plt.xlabel('Generation')\n",
        "#         plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "203XIKlCsjzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "052df68d-6e93-47dc-8c6d-691020fadc5a"
      },
      "source": [
        "# sel = GeneticSelector(estimator=RandomForestRegressor(), \n",
        "#                       n_gen=7, size=200, n_best=40, n_rand=40, \n",
        "#                       n_children=5, mutation_rate=0.05)\n",
        "# sel.fit(x, y_log)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-262-74a8e71f5055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                       \u001b[0mn_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       n_children=5, mutation_rate=0.05)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-261-33902614cf4a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitilize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-261-33902614cf4a>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Selection, crossover and mutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mscores_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-261-33902614cf4a>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchromosome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-196-9e45a3b3ff45>\u001b[0m in \u001b[0;36mmape\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred_log_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpred_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_log_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (35196,37) (35196,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rz_XdVDo2uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sel.support_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zrra5Nkqm-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C6TTiZlqnHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# select_VT = VarianceThreshold(0.00001)\n",
        "# x_VT = select_VT.fit_transform(x)\n",
        "# y_VT = select_VT.transform(y)\n",
        "# x_VT.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sSFJ89_qm7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = RandomForestRegressor()\n",
        "# model.fit(X_train_sel, y_train)\n",
        "# print(\"train accuracy:{:5.3f}\".format(accuracy_score(y_train, model.predict(X_train_sel))))\n",
        "# print(\"test accuracy :{:5.3f}\".format(accuracy_score(y_test, model.predict(X_test_sel))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8UVoq4x3PR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn42-BEo3H_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2cWQI5R3H9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import chi2, SelectKBest\n",
        "\n",
        "# select_SKB = SelectKBest(chi2, k=10000)\n",
        "# X_train_SKB = select_SKB.fit_transform(X_train)\n",
        "# X_test_SKB = select_SKB.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdemZ_3X3H6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0zXpz6c3H4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "013Lz03yo2qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHWTeOdHYC8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "b1dad0e7-ef23-419c-8039-5180a8d13d17"
      },
      "source": [
        "!pip install scikit-optimize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nlnysWVYbwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, TimeSeriesSplit, KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XToGOuwYb7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "db012923-5681-467a-8150-d216b796311b"
      },
      "source": [
        "ITERATIONS =20\n",
        "\n",
        "# tunning\n",
        "bayes_cv_tuner = BayesSearchCV(\n",
        "    estimator = RandomForestRegressor(\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    ),\n",
        "    search_spaces = {\n",
        "        'n_estimators': (30, 1000),\n",
        "        'min_samples_split': (2, 100),\n",
        "        'max_features': (0.1, 0.999, 'uniform'),\n",
        "        'max_features': ['auto', 'sqrt'],\n",
        "        'max_depth': (1, 20),\n",
        "        'min_samples_leaf':(1, 20) \n",
        "    },    \n",
        "    scoring = 'neg_mean_squared_log_error',\n",
        "    cv = KFold(\n",
        "        n_splits=5,\n",
        "    ),\n",
        "    n_jobs = -1,\n",
        "    n_iter = ITERATIONS,   \n",
        "    verbose = 0,\n",
        "    refit = True,\n",
        "    random_state = 529\n",
        ")\n",
        "\n",
        "def status_print(optim_result):\n",
        "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
        "      \n",
        "    # Get all the models tested so far in DataFrame format\n",
        "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
        "      \n",
        "    # Get current parameters and the best parameters    \n",
        "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
        "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
        "        len(all_models),\n",
        "        np.round(bayes_cv_tuner.best_score_, 4),\n",
        "        bayes_cv_tuner.best_params_\n",
        "    ))\n",
        "    # Save all model results\n",
        "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
        "    # all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
        "\n",
        "# Fit the model\n",
        "result = bayes_cv_tuner.fit(X_train, y_train_log, callback=status_print)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model #1\n",
            "Best ROC-AUC: -0.0008\n",
            "Best params: OrderedDict([('max_depth', 19), ('max_features', 'sqrt'), ('min_samples_leaf', 11), ('min_samples_split', 4), ('n_estimators', 227)])\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-db5c1ea1893e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_cv_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 optim_result = self._step(\n\u001b[1;32m    693\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m                 )\n\u001b[1;32m    696\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             )\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             for train, test in cv_iter)\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRkXQKKOYkNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_log = result.predict(X_test)\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa3NTVG8YkdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "ITERATIONS = 9\n",
        "# Classifier\n",
        "bayes_cv_tuner = BayesSearchCV(\n",
        "    estimator = lgb.LGBMRegressor(\n",
        "        objective='regression',\n",
        "        metric='rmsle',\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    ),\n",
        "    search_spaces = {\n",
        "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "        'num_leaves': (2, 600),      \n",
        "        'max_depth': (0, 60),\n",
        "        'min_child_samples': (0, 50),\n",
        "        'max_bin': (100, 1000),\n",
        "        'subsample': (0.01, 1.0, 'uniform'),\n",
        "        'subsample_freq': (0, 10),\n",
        "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
        "        'min_child_weight': (0, 10),\n",
        "        'subsample_for_bin': (100000, 500000),\n",
        "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
        "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
        "        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
        "        'n_estimators': (50, 100),\n",
        "    },    \n",
        "    scoring = 'neg_mean_squared_log_error',\n",
        "    cv = TimeSeriesSplit(\n",
        "        n_splits=4,\n",
        "    ),\n",
        "    n_jobs = -1,\n",
        "    n_iter = ITERATIONS,   \n",
        "    verbose = 0,\n",
        "    refit = True,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "def status_print(optim_result):\n",
        "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
        "      \n",
        "    # Get all the models tested so far in DataFrame format\n",
        "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
        "      \n",
        "    # Get current parameters and the best parameters    \n",
        "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
        "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
        "        len(all_models),\n",
        "        np.round(bayes_cv_tuner.best_score_, 4),\n",
        "        bayes_cv_tuner.best_params_\n",
        "    ))\n",
        "    # Save all model results\n",
        "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
        "    # all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
        "\n",
        "# Fit the model\n",
        "lgbm = bayes_cv_tuner.fit(X_train, y_train_log, callback=status_print)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5P97T42YmF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_log = lgbm.predict(X_test)\n",
        "pred_log_T = np.exp(1)**pred_log\n",
        "mape(y_test, pred_log_T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Td0foRoMx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}